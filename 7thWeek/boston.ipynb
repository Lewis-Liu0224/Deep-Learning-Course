{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.describe of         CRIM   ZN   INDUS   CHAS    NOX     RM   AGE     DIS  RAD  TAX  \\\n",
      "0    0.00632  18.0    2.31     0  0.538  6.575  65.2  4.0900    1  296   \n",
      "1    0.02731   0.0    7.07     0  0.469  6.421  78.9  4.9671    2  242   \n",
      "2    0.02729   0.0    7.07     0  0.469  7.185  61.1  4.9671    2  242   \n",
      "3    0.03237   0.0    2.18     0  0.458  6.998  45.8  6.0622    3  222   \n",
      "4    0.06905   0.0    2.18     0  0.458  7.147  54.2  6.0622    3  222   \n",
      "..       ...   ...     ...   ...    ...    ...   ...     ...  ...  ...   \n",
      "501  0.06263   0.0   11.93     0  0.573  6.593  69.1  2.4786    1  273   \n",
      "502  0.04527   0.0   11.93     0  0.573  6.120  76.7  2.2875    1  273   \n",
      "503  0.06076   0.0   11.93     0  0.573  6.976  91.0  2.1675    1  273   \n",
      "504  0.10959   0.0   11.93     0  0.573  6.794  89.3  2.3889    1  273   \n",
      "505  0.04741   0.0   11.93     0  0.573  6.030  80.8  2.5050    1  273   \n",
      "\n",
      "     PTRATIO  LSTAT  MEDV  \n",
      "0       15.3   4.98  24.0  \n",
      "1       17.8   9.14  21.6  \n",
      "2       17.8   4.03  34.7  \n",
      "3       18.7   2.94  33.4  \n",
      "4       18.7   5.33  36.2  \n",
      "..       ...    ...   ...  \n",
      "501     21.0   9.67  22.4  \n",
      "502     21.0   9.08  20.6  \n",
      "503     21.0   5.64  23.9  \n",
      "504     21.0   6.48  22.0  \n",
      "505     21.0   7.88  11.9  \n",
      "\n",
      "[506 rows x 13 columns]>\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"boston.csv\",header=0)\n",
    "print(df.describe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_data shape= (506, 12)\n",
      "y_data shape= (506,)\n"
     ]
    }
   ],
   "source": [
    "ds = df.values\n",
    "x_data = ds[:,:12]\n",
    "y_data = ds[:,12]\n",
    "for i in range(12):\n",
    "    x_data[:,i] = (x_data[:,i]-x_data[:,i].min())/(x_data[:,i].max()-x_data[:,i].min())\n",
    "print('x_data shape=',x_data.shape)\n",
    "print('y_data shape=',y_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_num = 300\n",
    "valid_num = 100\n",
    "test_num = len(x_data)- train_num -valid_num\n",
    "\n",
    "x_train = x_data[:train_num]\n",
    "y_train = y_data[:train_num]\n",
    "\n",
    "x_valid = x_data[train_num:train_num+valid_num]\n",
    "y_valid = y_data[train_num:train_num+valid_num]\n",
    "\n",
    "x_test = x_data[train_num+valid_num:train_num+valid_num+test_num]\n",
    "y_test = y_data[train_num+valid_num:train_num+valid_num+test_num]\n",
    "\n",
    "x_train = tf.cast(scale(x_train), dtype=tf.float32)\n",
    "x_valid = tf.cast(scale(x_valid), dtype=tf.float32)\n",
    "x_test = tf.cast(scale(x_test), dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=(12, 1) dtype=float32, numpy=\n",
      "array([[-0.3708039 ],\n",
      "       [-0.22504778],\n",
      "       [ 0.6215024 ],\n",
      "       [ 0.95534444],\n",
      "       [-0.83417124],\n",
      "       [ 0.82997173],\n",
      "       [-0.10736343],\n",
      "       [-0.4319501 ],\n",
      "       [ 0.47323957],\n",
      "       [-0.8861462 ],\n",
      "       [ 1.3418446 ],\n",
      "       [ 1.2536004 ]], dtype=float32)>\n",
      "<tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>\n"
     ]
    }
   ],
   "source": [
    "def model(x, w, b):\n",
    "    return tf.matmul(x,w)+ b\n",
    "\n",
    "W = tf.Variable(tf.random.normal([12,1],mean=0.0, stddev = 1.0, dtype=tf.float32))\n",
    "B = tf.Variable(tf.zeros(1), dtype = tf.float32)\n",
    "\n",
    "print(W)\n",
    "print(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_epochs = 200\n",
    "learning_rate = 0.0005\n",
    "batch_size = 10\n",
    "def loss(x,y,w,b):\n",
    "    err = model(x,w,b)-y\n",
    "    squared_err = tf.square(err)\n",
    "    return tf.reduce_mean(squared_err)\n",
    "def grad(x,y,w,b):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss_ = loss(x,y,w,b)\n",
    "    return tape.gradient(loss_, [w,b])\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=  1 ,train_loss=695.1601,valid_loss=491.2909\n",
      "epoch=  2 ,train_loss=659.2318,valid_loss=461.7909\n",
      "epoch=  3 ,train_loss=625.7086,valid_loss=434.6664\n",
      "epoch=  4 ,train_loss=594.3671,valid_loss=409.6500\n",
      "epoch=  5 ,train_loss=565.0190,valid_loss=386.5214\n",
      "epoch=  6 ,train_loss=537.5034,valid_loss=365.0980\n",
      "epoch=  7 ,train_loss=511.6807,valid_loss=345.2250\n",
      "epoch=  8 ,train_loss=487.4287,valid_loss=326.7707\n",
      "epoch=  9 ,train_loss=464.6390,valid_loss=309.6206\n",
      "epoch= 10 ,train_loss=443.2138,valid_loss=293.6747\n",
      "epoch= 11 ,train_loss=423.0650,valid_loss=278.8441\n",
      "epoch= 12 ,train_loss=404.1119,valid_loss=265.0493\n",
      "epoch= 13 ,train_loss=386.2802,valid_loss=252.2185\n",
      "epoch= 14 ,train_loss=369.5016,valid_loss=240.2863\n",
      "epoch= 15 ,train_loss=353.7126,valid_loss=229.1929\n",
      "epoch= 16 ,train_loss=338.8538,valid_loss=218.8829\n",
      "epoch= 17 ,train_loss=324.8700,valid_loss=209.3056\n",
      "epoch= 18 ,train_loss=311.7094,valid_loss=200.4136\n",
      "epoch= 19 ,train_loss=299.3234,valid_loss=192.1625\n",
      "epoch= 20 ,train_loss=287.6666,valid_loss=184.5114\n",
      "epoch= 21 ,train_loss=276.6960,valid_loss=177.4216\n",
      "epoch= 22 ,train_loss=266.3716,valid_loss=170.8575\n",
      "epoch= 23 ,train_loss=256.6554,valid_loss=164.7850\n",
      "epoch= 24 ,train_loss=247.5115,valid_loss=159.1725\n",
      "epoch= 25 ,train_loss=238.9066,valid_loss=153.9903\n",
      "epoch= 26 ,train_loss=230.8090,valid_loss=149.2105\n",
      "epoch= 27 ,train_loss=223.1888,valid_loss=144.8069\n",
      "epoch= 28 ,train_loss=216.0182,valid_loss=140.7551\n",
      "epoch= 29 ,train_loss=209.2707,valid_loss=137.0318\n",
      "epoch= 30 ,train_loss=202.9213,valid_loss=133.6153\n",
      "epoch= 31 ,train_loss=196.9468,valid_loss=130.4854\n",
      "epoch= 32 ,train_loss=191.3250,valid_loss=127.6228\n",
      "epoch= 33 ,train_loss=186.0352,valid_loss=125.0096\n",
      "epoch= 34 ,train_loss=181.0578,valid_loss=122.6291\n",
      "epoch= 35 ,train_loss=176.3744,valid_loss=120.4653\n",
      "epoch= 36 ,train_loss=171.9677,valid_loss=118.5034\n",
      "epoch= 37 ,train_loss=167.8213,valid_loss=116.7295\n",
      "epoch= 38 ,train_loss=163.9199,valid_loss=115.1306\n",
      "epoch= 39 ,train_loss=160.2492,valid_loss=113.6945\n",
      "epoch= 40 ,train_loss=156.7954,valid_loss=112.4096\n",
      "epoch= 41 ,train_loss=153.5458,valid_loss=111.2652\n",
      "epoch= 42 ,train_loss=150.4882,valid_loss=110.2512\n",
      "epoch= 43 ,train_loss=147.6114,valid_loss=109.3582\n",
      "epoch= 44 ,train_loss=144.9047,valid_loss=108.5774\n",
      "epoch= 45 ,train_loss=142.3580,valid_loss=107.9005\n",
      "epoch= 46 ,train_loss=139.9619,valid_loss=107.3198\n",
      "epoch= 47 ,train_loss=137.7075,valid_loss=106.8280\n",
      "epoch= 48 ,train_loss=135.5866,valid_loss=106.4184\n",
      "epoch= 49 ,train_loss=133.5910,valid_loss=106.0847\n",
      "epoch= 50 ,train_loss=131.7134,valid_loss=105.8208\n",
      "epoch= 51 ,train_loss=129.9470,valid_loss=105.6214\n",
      "epoch= 52 ,train_loss=128.2851,valid_loss=105.4812\n",
      "epoch= 53 ,train_loss=126.7216,valid_loss=105.3954\n",
      "epoch= 54 ,train_loss=125.2506,valid_loss=105.3595\n",
      "epoch= 55 ,train_loss=123.8667,valid_loss=105.3693\n",
      "epoch= 56 ,train_loss=122.5647,valid_loss=105.4210\n",
      "epoch= 57 ,train_loss=121.3398,valid_loss=105.5108\n",
      "epoch= 58 ,train_loss=120.1875,valid_loss=105.6354\n",
      "epoch= 59 ,train_loss=119.1035,valid_loss=105.7915\n",
      "epoch= 60 ,train_loss=118.0837,valid_loss=105.9763\n",
      "epoch= 61 ,train_loss=117.1244,valid_loss=106.1871\n",
      "epoch= 62 ,train_loss=116.2220,valid_loss=106.4211\n",
      "epoch= 63 ,train_loss=115.3731,valid_loss=106.6761\n",
      "epoch= 64 ,train_loss=114.5746,valid_loss=106.9500\n",
      "epoch= 65 ,train_loss=113.8235,valid_loss=107.2405\n",
      "epoch= 66 ,train_loss=113.1170,valid_loss=107.5459\n",
      "epoch= 67 ,train_loss=112.4525,valid_loss=107.8643\n",
      "epoch= 68 ,train_loss=111.8275,valid_loss=108.1942\n",
      "epoch= 69 ,train_loss=111.2396,valid_loss=108.5340\n",
      "epoch= 70 ,train_loss=110.6868,valid_loss=108.8824\n",
      "epoch= 71 ,train_loss=110.1668,valid_loss=109.2380\n",
      "epoch= 72 ,train_loss=109.6779,valid_loss=109.5997\n",
      "epoch= 73 ,train_loss=109.2181,valid_loss=109.9663\n",
      "epoch= 74 ,train_loss=108.7858,valid_loss=110.3369\n",
      "epoch= 75 ,train_loss=108.3793,valid_loss=110.7105\n",
      "epoch= 76 ,train_loss=107.9971,valid_loss=111.0862\n",
      "epoch= 77 ,train_loss=107.6377,valid_loss=111.4633\n",
      "epoch= 78 ,train_loss=107.3000,valid_loss=111.8410\n",
      "epoch= 79 ,train_loss=106.9824,valid_loss=112.2188\n",
      "epoch= 80 ,train_loss=106.6840,valid_loss=112.5959\n",
      "epoch= 81 ,train_loss=106.4035,valid_loss=112.9718\n",
      "epoch= 82 ,train_loss=106.1398,valid_loss=113.3461\n",
      "epoch= 83 ,train_loss=105.8921,valid_loss=113.7182\n",
      "epoch= 84 ,train_loss=105.6593,valid_loss=114.0878\n",
      "epoch= 85 ,train_loss=105.4406,valid_loss=114.4546\n",
      "epoch= 86 ,train_loss=105.2351,valid_loss=114.8181\n",
      "epoch= 87 ,train_loss=105.0421,valid_loss=115.1782\n",
      "epoch= 88 ,train_loss=104.8609,valid_loss=115.5343\n",
      "epoch= 89 ,train_loss=104.6907,valid_loss=115.8864\n",
      "epoch= 90 ,train_loss=104.5309,valid_loss=116.2342\n",
      "epoch= 91 ,train_loss=104.3809,valid_loss=116.5776\n",
      "epoch= 92 ,train_loss=104.2400,valid_loss=116.9164\n",
      "epoch= 93 ,train_loss=104.1079,valid_loss=117.2505\n",
      "epoch= 94 ,train_loss=103.9839,valid_loss=117.5796\n",
      "epoch= 95 ,train_loss=103.8676,valid_loss=117.9038\n",
      "epoch= 96 ,train_loss=103.7586,valid_loss=118.2230\n",
      "epoch= 97 ,train_loss=103.6563,valid_loss=118.5371\n",
      "epoch= 98 ,train_loss=103.5604,valid_loss=118.8459\n",
      "epoch= 99 ,train_loss=103.4706,valid_loss=119.1496\n",
      "epoch=100 ,train_loss=103.3864,valid_loss=119.4480\n",
      "epoch=101 ,train_loss=103.3076,valid_loss=119.7411\n",
      "epoch=102 ,train_loss=103.2338,valid_loss=120.0290\n",
      "epoch=103 ,train_loss=103.1647,valid_loss=120.3117\n",
      "epoch=104 ,train_loss=103.1001,valid_loss=120.5891\n",
      "epoch=105 ,train_loss=103.0397,valid_loss=120.8611\n",
      "epoch=106 ,train_loss=102.9832,valid_loss=121.1281\n",
      "epoch=107 ,train_loss=102.9305,valid_loss=121.3898\n",
      "epoch=108 ,train_loss=102.8812,valid_loss=121.6465\n",
      "epoch=109 ,train_loss=102.8352,valid_loss=121.8980\n",
      "epoch=110 ,train_loss=102.7924,valid_loss=122.1445\n",
      "epoch=111 ,train_loss=102.7524,valid_loss=122.3860\n",
      "epoch=112 ,train_loss=102.7151,valid_loss=122.6227\n",
      "epoch=113 ,train_loss=102.6805,valid_loss=122.8544\n",
      "epoch=114 ,train_loss=102.6483,valid_loss=123.0813\n",
      "epoch=115 ,train_loss=102.6183,valid_loss=123.3035\n",
      "epoch=116 ,train_loss=102.5906,valid_loss=123.5210\n",
      "epoch=117 ,train_loss=102.5648,valid_loss=123.7339\n",
      "epoch=118 ,train_loss=102.5410,valid_loss=123.9424\n",
      "epoch=119 ,train_loss=102.5189,valid_loss=124.1462\n",
      "epoch=120 ,train_loss=102.4986,valid_loss=124.3458\n",
      "epoch=121 ,train_loss=102.4798,valid_loss=124.5411\n",
      "epoch=122 ,train_loss=102.4625,valid_loss=124.7321\n",
      "epoch=123 ,train_loss=102.4466,valid_loss=124.9190\n",
      "epoch=124 ,train_loss=102.4321,valid_loss=125.1019\n",
      "epoch=125 ,train_loss=102.4188,valid_loss=125.2807\n",
      "epoch=126 ,train_loss=102.4067,valid_loss=125.4556\n",
      "epoch=127 ,train_loss=102.3956,valid_loss=125.6266\n",
      "epoch=128 ,train_loss=102.3856,valid_loss=125.7940\n",
      "epoch=129 ,train_loss=102.3766,valid_loss=125.9576\n",
      "epoch=130 ,train_loss=102.3686,valid_loss=126.1177\n",
      "epoch=131 ,train_loss=102.3613,valid_loss=126.2742\n",
      "epoch=132 ,train_loss=102.3549,valid_loss=126.4273\n",
      "epoch=133 ,train_loss=102.3493,valid_loss=126.5769\n",
      "epoch=134 ,train_loss=102.3444,valid_loss=126.7233\n",
      "epoch=135 ,train_loss=102.3401,valid_loss=126.8664\n",
      "epoch=136 ,train_loss=102.3365,valid_loss=127.0064\n",
      "epoch=137 ,train_loss=102.3335,valid_loss=127.1433\n",
      "epoch=138 ,train_loss=102.3310,valid_loss=127.2771\n",
      "epoch=139 ,train_loss=102.3291,valid_loss=127.4079\n",
      "epoch=140 ,train_loss=102.3277,valid_loss=127.5359\n",
      "epoch=141 ,train_loss=102.3267,valid_loss=127.6611\n",
      "epoch=142 ,train_loss=102.3262,valid_loss=127.7835\n",
      "epoch=143 ,train_loss=102.3261,valid_loss=127.9033\n",
      "epoch=144 ,train_loss=102.3264,valid_loss=128.0204\n",
      "epoch=145 ,train_loss=102.3270,valid_loss=128.1349\n",
      "epoch=146 ,train_loss=102.3280,valid_loss=128.2469\n",
      "epoch=147 ,train_loss=102.3294,valid_loss=128.3565\n",
      "epoch=148 ,train_loss=102.3310,valid_loss=128.4638\n",
      "epoch=149 ,train_loss=102.3329,valid_loss=128.5687\n",
      "epoch=150 ,train_loss=102.3350,valid_loss=128.6714\n",
      "epoch=151 ,train_loss=102.3374,valid_loss=128.7717\n",
      "epoch=152 ,train_loss=102.3401,valid_loss=128.8701\n",
      "epoch=153 ,train_loss=102.3430,valid_loss=128.9662\n",
      "epoch=154 ,train_loss=102.3461,valid_loss=129.0603\n",
      "epoch=155 ,train_loss=102.3493,valid_loss=129.1525\n",
      "epoch=156 ,train_loss=102.3528,valid_loss=129.2427\n",
      "epoch=157 ,train_loss=102.3564,valid_loss=129.3310\n",
      "epoch=158 ,train_loss=102.3602,valid_loss=129.4173\n",
      "epoch=159 ,train_loss=102.3641,valid_loss=129.5019\n",
      "epoch=160 ,train_loss=102.3682,valid_loss=129.5848\n",
      "epoch=161 ,train_loss=102.3724,valid_loss=129.6659\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=162 ,train_loss=102.3767,valid_loss=129.7453\n",
      "epoch=163 ,train_loss=102.3812,valid_loss=129.8232\n",
      "epoch=164 ,train_loss=102.3857,valid_loss=129.8994\n",
      "epoch=165 ,train_loss=102.3903,valid_loss=129.9741\n",
      "epoch=166 ,train_loss=102.3951,valid_loss=130.0473\n",
      "epoch=167 ,train_loss=102.3999,valid_loss=130.1190\n",
      "epoch=168 ,train_loss=102.4048,valid_loss=130.1892\n",
      "epoch=169 ,train_loss=102.4098,valid_loss=130.2581\n",
      "epoch=170 ,train_loss=102.4148,valid_loss=130.3256\n",
      "epoch=171 ,train_loss=102.4199,valid_loss=130.3917\n",
      "epoch=172 ,train_loss=102.4251,valid_loss=130.4566\n",
      "epoch=173 ,train_loss=102.4303,valid_loss=130.5202\n",
      "epoch=174 ,train_loss=102.4356,valid_loss=130.5826\n",
      "epoch=175 ,train_loss=102.4409,valid_loss=130.6438\n",
      "epoch=176 ,train_loss=102.4462,valid_loss=130.7039\n",
      "epoch=177 ,train_loss=102.4516,valid_loss=130.7628\n",
      "epoch=178 ,train_loss=102.4571,valid_loss=130.8205\n",
      "epoch=179 ,train_loss=102.4626,valid_loss=130.8773\n",
      "epoch=180 ,train_loss=102.4680,valid_loss=130.9329\n",
      "epoch=181 ,train_loss=102.4736,valid_loss=130.9875\n",
      "epoch=182 ,train_loss=102.4791,valid_loss=131.0412\n",
      "epoch=183 ,train_loss=102.4847,valid_loss=131.0938\n",
      "epoch=184 ,train_loss=102.4903,valid_loss=131.1455\n",
      "epoch=185 ,train_loss=102.4959,valid_loss=131.1963\n",
      "epoch=186 ,train_loss=102.5015,valid_loss=131.2462\n",
      "epoch=187 ,train_loss=102.5072,valid_loss=131.2952\n",
      "epoch=188 ,train_loss=102.5128,valid_loss=131.3433\n",
      "epoch=189 ,train_loss=102.5185,valid_loss=131.3906\n",
      "epoch=190 ,train_loss=102.5242,valid_loss=131.4371\n",
      "epoch=191 ,train_loss=102.5298,valid_loss=131.4828\n",
      "epoch=192 ,train_loss=102.5355,valid_loss=131.5278\n",
      "epoch=193 ,train_loss=102.5412,valid_loss=131.5720\n",
      "epoch=194 ,train_loss=102.5469,valid_loss=131.6154\n",
      "epoch=195 ,train_loss=102.5526,valid_loss=131.6582\n",
      "epoch=196 ,train_loss=102.5583,valid_loss=131.7002\n",
      "epoch=197 ,train_loss=102.5640,valid_loss=131.7415\n",
      "epoch=198 ,train_loss=102.5696,valid_loss=131.7822\n",
      "epoch=199 ,train_loss=102.5753,valid_loss=131.8223\n",
      "epoch=200 ,train_loss=102.5810,valid_loss=131.8617\n"
     ]
    }
   ],
   "source": [
    "loss_list_train = []\n",
    "loss_list_valid = []\n",
    "total_step = int (train_num/batch_size)\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    for step in range(total_step):\n",
    "        xs = x_train[step*batch_size:(step+1)*batch_size,:]\n",
    "        ys = y_train[step*batch_size:(step+1)*batch_size]\n",
    "        \n",
    "        grads = grad(xs,ys,W,B)\n",
    "        optimizer.apply_gradients(zip(grads,[W,B]))\n",
    "        \n",
    "    loss_train = loss(x_train, y_train,W ,B).numpy()\n",
    "    loss_valid = loss(x_valid, y_valid,W ,B).numpy()\n",
    "    loss_list_train.append(loss_train)\n",
    "    loss_list_valid.append(loss_valid)\n",
    "    print(\"epoch={:3d} ,train_loss={:.4f},valid_loss={:.4f}\".format(epoch+1,loss_train,loss_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test_loss:136.0787\n",
      "<tf.Variable 'Variable:0' shape=(12, 1) dtype=float32, numpy=\n",
      "array([[ 0.29020333],\n",
      "       [ 0.2885908 ],\n",
      "       [-0.64415365],\n",
      "       [ 0.69968086],\n",
      "       [-2.180317  ],\n",
      "       [ 1.5975026 ],\n",
      "       [-0.06919503],\n",
      "       [-1.2852566 ],\n",
      "       [ 0.50730675],\n",
      "       [-0.5218967 ],\n",
      "       [-2.6796637 ],\n",
      "       [-0.6442877 ]], dtype=float32)>\n",
      "<tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([25.431242], dtype=float32)>\n"
     ]
    }
   ],
   "source": [
    "print(\"Test_loss:{:.4f}\".format(loss(x_test, y_test, W, B).numpy()))\n",
    "#print(\"W:{:.4f}\".format(W.numpy()))\n",
    "#print(\"B:{:.4f}\".format(B))\n",
    "print(W)\n",
    "print(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
